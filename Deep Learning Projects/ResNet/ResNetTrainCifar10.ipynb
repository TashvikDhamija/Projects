{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA TRANSFORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose(\n",
    "                [T.ToTensor(),T.Normalize((0.5,),(0.5,))]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import sampler,DataLoader\n",
    "\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "trainSet = dset.CIFAR10(root = 'OneDrive/Documents/Machine Learning/DL/', \n",
    "                             train=True, \n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, \n",
    "                          batch_size=128, \n",
    "                          sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "valSet = dset.CIFAR10(root = 'OneDrive/Documents/Machine Learning/DL/', \n",
    "                           train=True, \n",
    "                           download=True,\n",
    "                           transform=transform)\n",
    "\n",
    "valLoader = DataLoader(valSet, \n",
    "                        batch_size=128, \n",
    "                        sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "testSet = dset.CIFAR10(root = 'OneDrive/Documents/Machine Learning/DL/', \n",
    "                            train=False, \n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "testLoader = DataLoader(testSet, \n",
    "                         batch_size=128)\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALIZING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,12))\n",
    "for i in range(1,17):\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(trainSet.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainSet.data.shape)\n",
    "print(testSet.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING and ACCURACY FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,loss_func,opt,lr,num_epoch=1):\n",
    "    iteration = 0\n",
    "    loss_list = []\n",
    "    iter_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"Epoch %d/%d\"%(epoch+1,num_epoch))\n",
    "        net.train()\n",
    "        for i,data in enumerate(trainLoader,0):\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Using GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Wrapping in Variable\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # Clearing previous gradients\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Forward Propagation\n",
    "            scores = net(inputs)\n",
    "            loss = loss_func(scores,labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            iteration += 1\n",
    "            if iteration % 100 == 0:\n",
    "                loss_list.append(loss)\n",
    "                iter_list.append(iteration)\n",
    "                # Print Loss\n",
    "                print('Iteration: %d, loss = %0.7f'%(iteration,loss))\n",
    "            \n",
    "        val_acc = check_accuracy(net,valLoader)\n",
    "        val_acc_list.append(val_acc)\n",
    "        if (epoch+1) % 15 == 0:\n",
    "            lr /= 3\n",
    "            update_lr(opt, lr)\n",
    "    \n",
    "    return iter_list,loss_list,val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize(iter_l,loss_l,val_l,epochs=1):\n",
    "    # visualizing loss function\n",
    "    plt.plot(iter_l,loss_l)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Optimizing Lost function over CIFAR10 Dataset')\n",
    "    plt.show()\n",
    "\n",
    "    #visualizing Val Accuracy\n",
    "    plt.plot(np.arange(epochs),val_l)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Validation Set')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model,loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on Validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on Test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    for i,data in enumerate(loader,0):\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Using GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward Propagation\n",
    "            scores = model(inputs)\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(scores.data, 1)[1]\n",
    "                \n",
    "            # Total number of labels\n",
    "            num_samples += len(labels)\n",
    "                \n",
    "            num_correct += (predicted == labels).sum()\n",
    "            \n",
    "    accuracy = 100 * num_correct / float(num_samples)\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN MODEL FOR CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels,out_channels,stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels,out_channels,stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels,out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self,x):\n",
    "        res = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            res = self.downsample(x)\n",
    "        out += res\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,block,layers,num_classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels = 16\n",
    "        \n",
    "        self.conv = conv3x3(3,16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block,16,layers[0])\n",
    "        self.layer2 = self.make_layer(block,32,layers[1],2)\n",
    "        self.layer3 = self.make_layer(block,64,layers[2],2)\n",
    "        self.layer4 = self.make_layer(block,128,layers[3],2)\n",
    "        self.maxpool = nn.MaxPool2d(4)\n",
    "        self.fc = nn.Linear(128,num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self,block,out_channels,layer,stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                            conv3x3(self.in_channels,out_channels,stride=stride),\n",
    "                            nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels,out_channels,stride,downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1,layer):\n",
    "            layers.append(block(out_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available:\",torch.cuda.is_available())\n",
    "print(\"Number of GPU available:\",torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINING NET, LOSS AND OPTIMIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 45\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(ResidualBlock,[2,2,2,2]).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(params = net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING and VIZUALISATION of MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = train(net,loss_func,opt,learning_rate,num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualize(a,b,c,num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check_accuracy(net,testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(net,trainLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'resnet_cifar10.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
